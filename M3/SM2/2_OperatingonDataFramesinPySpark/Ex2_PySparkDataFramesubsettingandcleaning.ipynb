{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark DataFrame subsetting and cleaning\n",
    "\n",
    "- After data inspection, it is often necessary to clean the data which mainly involves subsetting, renaming the columns, removing duplicated rows etc., PySpark DataFrame API provides several operators to do this. In this exercise, your job is to subset `'name'`, `'sex'` and `'date of birth'` columns from `people_df` DataFrame, remove any duplicate rows from that dataset and count the number of rows before and after duplicates removal step.\n",
    "\n",
    "- Remember, you already have `SparkSession` `spark` and `people_df` DataFrames available in your workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "- Select `'name'`, `'sex'` and `'date of birth'` columns from `people_df` and create `people_df_sub` DataFrame.\n",
    "- Print the first 10 observations in the `people_df` DataFrame.\n",
    "- Remove duplicate entries from `people_df_sub` DataFrame and create `people_df_sub_nodup` DataFrame.\n",
    "- How many rows are there before and after duplicates are removed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+-------------+\n",
      "|            name|   sex|date of birth|\n",
      "+----------------+------+-------------+\n",
      "|  Penelope Lewis|female|   1990-08-31|\n",
      "|   David Anthony|  male|   1971-10-14|\n",
      "|       Ida Shipp|female|   1962-05-24|\n",
      "|    Joanna Moore|female|   2017-03-10|\n",
      "|  Lisandra Ortiz|female|   2020-08-05|\n",
      "|   David Simmons|  male|   1999-12-30|\n",
      "|   Edward Hudson|  male|   1983-05-09|\n",
      "|    Albert Jones|  male|   1990-09-13|\n",
      "|Leonard Cavender|  male|   1958-08-08|\n",
      "|  Everett Vadala|  male|   2005-05-24|\n",
      "+----------------+------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "There were 100000 rows before removing duplicates, and 99998 rows after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "file_path = \"file:///home/talentum/test-jupyter/P2/M3/SM2/2_OperatingonDataFramesinPySpark/Dataset/people.csv\"\n",
    "\n",
    "# Create an DataFrame from file_path\n",
    "people_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Select name, sex and date of birth columns\n",
    "people_df_sub = people_df.select('name', 'sex', 'date of birth')\n",
    "\n",
    "# Print the first 10 observations from people_df_sub\n",
    "people_df_sub.show(10)\n",
    "\n",
    "# Remove duplicate entries from people_df_sub\n",
    "people_df_sub_nodup = people_df_sub.dropDuplicates()\n",
    "\n",
    "# Count the number of rows\n",
    "print(\"There were {} rows before removing duplicates, and {} rows after removing duplicates\".format(people_df_sub.count(), people_df_sub_nodup.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------------+-----+\n",
      "|         name|   sex|date of birth|count|\n",
      "+-------------+------+-------------+-----+\n",
      "|Kathryn Davis|female|  20175-02-28|    2|\n",
      "| Robert Smith|  male|  20175-02-28|    2|\n",
      "+-------------+------+-------------+-----+\n",
      "\n",
      "<class 'pyspark.sql.group.GroupedData'>\n"
     ]
    }
   ],
   "source": [
    "#to see duplicated records\n",
    "#people_df_sub.groupBy(people_df_sub.columns).count().filter(\"count > 1\").show()\n",
    "people_df_sub.groupBy('name', 'sex','date of birth').count().filter(\"count > 1\").show()\n",
    "print(type(people_df_sub.groupBy('name', 'sex','date of birth')))\n",
    "#this columns are of string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------------+-----+\n",
      "|         name|   sex|date of birth|count|\n",
      "+-------------+------+-------------+-----+\n",
      "|Kathryn Davis|female|  20175-02-28|    2|\n",
      "| Robert Smith|  male|  20175-02-28|    2|\n",
      "+-------------+------+-------------+-----+\n",
      "\n",
      "<class 'pyspark.sql.column.Column'>\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.groupBy(people_df_sub.name,people_df_sub.sex,'date of birth').count().where('count > 1').show()\n",
    "print(type(people_df_sub.name))#this columns are of object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.column.Column'>\n",
      "+-------------+------+-------------+-----+\n",
      "|         name|   sex|date of birth|count|\n",
      "+-------------+------+-------------+-----+\n",
      "|Kathryn Davis|female|  20175-02-28|    2|\n",
      "| Robert Smith|  male|  20175-02-28|    2|\n",
      "+-------------+------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#people_df_sub.groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub.date of birth).count().where('count > 1').show()\n",
    "#above line will give error for date of birth as it is a object\n",
    "print(type(people_df_sub['date of birth'])) #this is a column object\n",
    "people_df_sub.groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']).count().where('count > 1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(people_df_sub.groupBy('name','sex','date of birth').count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- date of birth: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- date of birth: string (nullable = true)\n",
      " |-- count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub.groupBy('name','sex','date of birth').count().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------------+-----+\n",
      "|         name|   sex|date of birth|count|\n",
      "+-------------+------+-------------+-----+\n",
      "|Kathryn Davis|female|  20175-02-28|    2|\n",
      "| Robert Smith|  male|  20175-02-28|    2|\n",
      "+-------------+------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "people_df_sub \\\n",
    ".groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']) \\\n",
    ".count().where('count > 1').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### object oriented programming  and functional orirnted programming example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+-------------+-----+\n",
      "|         name|   sex|date of birth|count|\n",
      "+-------------+------+-------------+-----+\n",
      "|Kathryn Davis|female|  20175-02-28|    2|\n",
      "| Robert Smith|  male|  20175-02-28|    2|\n",
      "+-------------+------+-------------+-----+\n",
      "\n",
      "<class 'pyspark.sql.column.Column'>\n",
      "[Row(name='Kathryn Davis', sex='female', date of birth='20175-02-28', count=2), Row(name='Robert Smith', sex='male', date of birth='20175-02-28', count=2)]\n"
     ]
    }
   ],
   "source": [
    "# people_df_sub \\\n",
    "# .groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']) \\\n",
    "# .count().where(people_df_sub.count > 1).show()\n",
    "# #TypeError: '>' not supported between instances of 'method' and 'int'\n",
    "\n",
    "#--------------------------------\n",
    "# people_df_sub \\\n",
    "# .groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']) \\\n",
    "# .count().where(people_df_sub['count'] > 1).show()\n",
    "# #AnalysisException: 'Cannot resolve column name \"count\" among (name, sex, date of birth);'\n",
    "# #here where(people_df_sub['count'] > 1) is try look for count column which not present\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "#to insist where(people_df_sub['count'] > 1) that it is a column \n",
    "#use below\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#using column objects\n",
    "people_df_sub \\\n",
    ".groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']) \\\n",
    ".count().where(col('count')>1).show() \n",
    "\n",
    "print(type(col('count')>1)) #its a column object\n",
    "\n",
    "#in pandas series object even row is series object\n",
    "#in spark data frame columns are column object\n",
    "#in spark data frame rows are row object object\n",
    "#spark data frame is collection of row and columns objects\n",
    "#pandas df is immutable\n",
    "#pandas df is not a distributed data structure\n",
    "#spark df is distributed data structure\n",
    "\n",
    "print(people_df_sub \\\n",
    ".groupBy(people_df_sub.name,people_df_sub.sex,people_df_sub['date of birth']) \\\n",
    ".count().where(col('count')>1).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
